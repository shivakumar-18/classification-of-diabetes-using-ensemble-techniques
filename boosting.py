# -*- coding: utf-8 -*-
"""Boosting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16w7LURPtJobNn3A9ZDBbmCTfScdaJT_v
"""

# AdaBoost

from sklearn import model_selection 
from sklearn.ensemble import AdaBoostClassifier 
from sklearn.tree import DecisionTreeClassifier 
import pandas as pd 
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
import os
import psutil

dataset = pd.read_csv("pima-indians-diabetes.csv")
dataset.shape

Accuracy_Scores = []
precision_scores = []
recall_scores = []
f_score_scores = []
cpu_usage = []
ram_usage = []

dataset.columns = ['PN', 'PGC', 'BP', 'SFT', 'SI', 'BMI' , 'DPF', 'Age', 'Class']
dataset.head()

dataset.isna().sum()

dataset.describe()

X = dataset.iloc[:,:-1]
y = dataset.iloc[:,-1]

print(X.shape)
print(y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Decision Tree
seed = 8
kfold = model_selection.KFold(n_splits = 3,random_state = None)
base_cls = DecisionTreeClassifier() 
num_trees = 10
model = AdaBoostClassifier(base_estimator = base_cls, n_estimators = num_trees, random_state = seed) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Decision Tree:")
print("Model Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
Accuracy_Scores.append(metrics.accuracy_score(y_test, y_pred)*100)
print("Precision Score:",precision_score(y_test,y_pred))
precision_scores.append(precision_score(y_test,y_pred))
print("Recall Score:",recall_score(y_test,y_pred))
recall_scores.append(recall_score(y_test,y_pred))
print("f1-Score:",f1_score(y_test,y_pred))
f_score_scores.append(f1_score(y_test,y_pred))


probs = model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)


plt.title('Boosting-DecisionTree')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

import psutil
cpu_usg = psutil.cpu_percent()
cpu_usage.append(cpu_usg)
print('CPU % used:',cpu_usg)

ram_usg = psutil.virtual_memory()[2]
ram_usage.append(ram_usg)
print('RAM memory % used:', ram_usg)

# Decision Tree
seed = 8
kfold = model_selection.KFold(n_splits = 3,random_state = None)
base_cls = DecisionTreeClassifier() 
num_trees = 20
model = AdaBoostClassifier(base_estimator = base_cls, n_estimators = num_trees, random_state = seed) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Decision Tree:")
print("Model Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
Accuracy_Scores.append(metrics.accuracy_score(y_test, y_pred)*100)
print("Precision Score:",precision_score(y_test,y_pred))
precision_scores.append(precision_score(y_test,y_pred))
print("Recall Score:",recall_score(y_test,y_pred))
recall_scores.append(recall_score(y_test,y_pred))
print("f1-Score:",f1_score(y_test,y_pred))
f_score_scores.append(f1_score(y_test,y_pred))


probs = model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)


plt.title('Boosting-DecisionTree')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

import psutil
cpu_usg = psutil.cpu_percent()
cpu_usage.append(cpu_usg)
print('CPU % used:',cpu_usg)

ram_usg = psutil.virtual_memory()[2]
ram_usage.append(ram_usg)
print('RAM memory % used:', ram_usg)

# Decision Tree
seed = 8
kfold = model_selection.KFold(n_splits = 3,random_state = None)
base_cls = DecisionTreeClassifier() 
num_trees = 50
model = AdaBoostClassifier(base_estimator = base_cls, n_estimators = num_trees, random_state = seed) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Decision Tree:")
print("Model Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
Accuracy_Scores.append(metrics.accuracy_score(y_test, y_pred)*100)
print("Precision Score:",precision_score(y_test,y_pred))
precision_scores.append(precision_score(y_test,y_pred))
print("Recall Score:",recall_score(y_test,y_pred))
recall_scores.append(recall_score(y_test,y_pred))
print("f1-Score:",f1_score(y_test,y_pred))
f_score_scores.append(f1_score(y_test,y_pred))


probs = model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)


plt.title('Boosting-DecisionTree')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

import psutil
cpu_usg = psutil.cpu_percent()
cpu_usage.append(cpu_usg)
print('CPU % used:',cpu_usg)

ram_usg = psutil.virtual_memory()[2]
ram_usage.append(ram_usg)
print('RAM memory % used:', ram_usg)

from sklearn.naive_bayes import GaussianNB
base_cls = GaussianNB() 
model = AdaBoostClassifier(base_estimator = base_cls, n_estimators = 10) 
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Naive Bayes:")
print("Model Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
Accuracy_Scores.append(metrics.accuracy_score(y_test, y_pred)*100)
print("Precision Score:",precision_score(y_test,y_pred))
precision_scores.append(precision_score(y_test,y_pred))
print("Recall Score:",recall_score(y_test,y_pred))
recall_scores.append(recall_score(y_test,y_pred))
print("f1-Score:",f1_score(y_test,y_pred))
f_score_scores.append(f1_score(y_test,y_pred))



probs = model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)


plt.title('Boosting-Naive Bayes')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

import psutil
cpu_usg = psutil.cpu_percent()
cpu_usage.append(cpu_usg)
print('CPU % used:',cpu_usg)

ram_usg = psutil.virtual_memory()[2]
ram_usage.append(ram_usg)
print('RAM memory % used:', ram_usg)

from sklearn.svm import SVC
from sklearn import metrics
svc=SVC(probability=True, kernel='linear')

abc =AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)

model = abc.fit(X_train, y_train)
y_pred = model.predict(X_test)


# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

print("SVC:")
print("Model Accuracy:",metrics.accuracy_score(y_test, y_pred)*100)
Accuracy_Scores.append(metrics.accuracy_score(y_test, y_pred)*100)
print("Precision Score:",precision_score(y_test,y_pred))
precision_scores.append(precision_score(y_test,y_pred))
print("Recall Score:",recall_score(y_test,y_pred))
recall_scores.append(recall_score(y_test,y_pred))
print("f1-Score:",f1_score(y_test,y_pred))
f_score_scores.append(f1_score(y_test,y_pred))



probs = model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)


plt.title('Boosting-SVC')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

import psutil
cpu_usg = psutil.cpu_percent()
cpu_usage.append(cpu_usg)
print('CPU % used:',cpu_usg)

ram_usg = psutil.virtual_memory()[2]
ram_usage.append(ram_usg)
print('RAM memory % used:', ram_usg)



import numpy as np
print("accuracy:",Accuracy_Scores)
print("precision:",np.array(precision_scores)*100)
print("recall:",np.array(recall_scores)*100)
print("f-score:",np.array(f_score_scores)*100)
print("cpu usage:",cpu_usage)
print("ram usage:",ram_usage)

import seaborn as sns
models = [
          'Decision Tree',
          'Random Forest',
          'Naive Bayes',
          'SVC']
models = pd.DataFrame({'Model' : models, 'Accuracy' : Accuracy_Scores})
plt.figure(figsize = (6,8))
plt.title("Boosting Accuracy")
sns.barplot(x = 'Model', y = 'Accuracy', data = models)
plt.show()

print(ram_usage)
print(cpu_usage)

models = [
          'Decision Tree',
          'Random Forest',
          'Naive Bayes',
          'SVC']

models = pd.DataFrame({'Model' : models, 'Ram usage' : ram_usage})
plt.figure(figsize = (6,8))
plt.title("Boosting Ram usage")
sns.barplot(x = 'Model', y = 'Ram usage', data = models)
plt.show()

models = [
          'Decision Tree',
          'Random Forest',
          'Naive Bayes',
          'SVC']

models = pd.DataFrame({'Model' : models, 'Cpu usage' : cpu_usage})
plt.figure(figsize = (6,8))
plt.title("Boosting Cpu usage")
sns.barplot(x = 'Model', y = 'Cpu usage', data = models)
plt.show()